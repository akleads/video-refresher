---
phase: 07-ffmpeg-processing-engine
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - server/lib/processor.js
  - server/lib/queue.js
autonomous: true

must_haves:
  truths:
    - "A queued job is automatically picked up and processed without manual intervention"
    - "Each source video in a job produces N variation output files with unique random effects"
    - "Progress percentage updates in SQLite as FFmpeg encodes each variation"
    - "A failed video file does not block processing of remaining files in the batch"
    - "Jobs continue processing after the API client disconnects (fire-and-forget)"
  artifacts:
    - path: "server/lib/processor.js"
      provides: "Per-file video processing: probe, generate effects, spawn FFmpeg per variation, update DB"
      exports: ["processJob"]
    - path: "server/lib/queue.js"
      provides: "Job queue worker polling SQLite for queued jobs, processing one at a time"
      exports: ["JobQueueWorker"]
  key_links:
    - from: "server/lib/processor.js"
      to: "server/lib/ffmpeg.js"
      via: "imports spawnFFmpeg and getVideoDuration"
      pattern: "import.*from.*ffmpeg"
    - from: "server/lib/processor.js"
      to: "server/lib/effects.js"
      via: "imports generateUniqueEffects and buildFilterString"
      pattern: "import.*from.*effects"
    - from: "server/lib/processor.js"
      to: "server/db/queries.js"
      via: "updates progress, status, output files in SQLite"
      pattern: "queries\\.(updateFile|insertOutput|updateJob)"
    - from: "server/lib/queue.js"
      to: "server/lib/processor.js"
      via: "calls processJob for each queued job"
      pattern: "processJob"
    - from: "server/lib/queue.js"
      to: "SQLite polling"
      via: "getNextQueuedJob every 2 seconds"
      pattern: "getNextQueuedJob"
---

<objective>
Build the video processing orchestrator and job queue worker that turn uploaded videos into variations using the FFmpeg wrapper and effects generator from Plan 07-01.

Purpose: This is the core processing engine -- the reason v2 exists. The processor takes a job, iterates its files, generates unique effects per variation, spawns FFmpeg for each, tracks progress in SQLite, and handles per-file failures gracefully. The queue worker polls for queued jobs and drives processing in the background.

Output: Two new modules -- processor.js (per-job processing logic) and queue.js (background worker).
</objective>

<execution_context>
@/Users/alexkozhemiachenko/.claude/get-shit-done/workflows/execute-plan.md
@/Users/alexkozhemiachenko/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ffmpeg-processing-engine/07-RESEARCH.md
@.planning/phases/07-ffmpeg-processing-engine/07-01-SUMMARY.md
@server/db/schema.js
@server/db/queries.js
@server/lib/ffmpeg.js
@server/lib/effects.js
@server/lib/id.js
@server/index.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create video processor module</name>
  <files>server/lib/processor.js</files>
  <action>
  Create `server/lib/processor.js` that exports a single function:

  **`processJob(job, db, queries, outputDir)`** -- Processes all files in a job, generating variations for each.

  Implementation:

  ```
  async function processJob(job, db, queries, outputDir) {
    // 1. Update job status to 'processing'
    queries.updateJobStatus.run('processing', job.id);

    // 2. Get all files for this job
    const files = queries.getJobFiles.all(job.id);

    // 3. Determine variations per video
    //    total_variations / total_videos = variationsPerVideo
    const variationsPerVideo = Math.round(job.total_variations / job.total_videos);

    let allSucceeded = true;

    // 4. Process each file
    for (const file of files) {
      try {
        await processFile(file, job, variationsPerVideo, db, queries, outputDir);
        queries.updateFileStatus.run('completed', file.id);
      } catch (err) {
        allSucceeded = false;
        queries.updateFileError.run(err.message, file.id);
        console.error(`File ${file.id} (${file.original_name}) failed:`, err.message);
        // Continue to next file -- don't block batch (Success Criteria #5)
      }
    }

    // 5. Mark job as completed or partial_failure
    if (allSucceeded) {
      queries.updateJobStatus.run('completed', job.id);
    } else {
      // Check if ANY files succeeded
      const completedFiles = files.filter(f => {
        const updated = queries.getJobFiles.all(job.id);
        return updated.find(u => u.id === f.id)?.status === 'completed';
      });
      // Re-query to get current status
      const updatedFiles = queries.getJobFiles.all(job.id);
      const anyCompleted = updatedFiles.some(f => f.status === 'completed');
      const allFailed = updatedFiles.every(f => f.status === 'failed');

      if (allFailed) {
        queries.updateJobError.run('All videos failed to process', job.id);
      } else {
        queries.updateJobStatus.run('completed', job.id);
        // Job is "completed" even if some files failed -- partial success
      }
    }
  }
  ```

  **`processFile(file, job, variationsPerVideo, db, queries, outputDir)`** (internal, not exported):

  1. Update file status to 'processing': `queries.updateFileStatus.run('processing', file.id)`
  2. Get video duration: `const duration = await getVideoDuration(file.upload_path)`
  3. Store duration: `queries.updateFileDuration.run(duration, file.id)`
  4. Generate unique effects: `const effects = generateUniqueEffects(variationsPerVideo)`
  5. Create job-specific output directory: `${outputDir}/${job.id}` (mkdir -p)
  6. For each variation (index 0 to variationsPerVideo-1):
     a. Build filter string from effects[i]
     b. Generate output filename: `${path.basename(file.original_name, '.mp4')}_var${i+1}_${generateId()}.mp4`
     c. Build output path: `${outputDir}/${job.id}/${outputFilename}`
     d. Call `spawnFFmpeg(file.upload_path, outputPath, filterString, onProgress, duration)`
     e. Store pid: `queries.updateFilePid.run(ffmpegResult.process.pid, file.id)`
     f. Await ffmpegResult.promise
     g. Clear pid: `queries.updateFilePid.run(null, file.id)`
     h. Get output file size with fs.statSync
     i. Insert output file record: `queries.insertOutputFile.run(generateId(), job.id, file.id, i, outputPath, fileSize)`
     j. Increment completed variations: `queries.incrementFileVariations.run(file.id)`
  7. The `onProgress` callback should compute overall file progress. Define it as a closure inside the file loop, capturing the current variation index:

     ```javascript
     // Inside processFile, before the variation loop:
     let lastWrittenProgress = -1;

     // Inside the variation for-loop, for variation index `i`:
     const onProgress = (percent) => {
       const overall = Math.round((i * 100 + percent) / variationsPerVideo);
       if (Math.abs(overall - lastWrittenProgress) >= 2) {
         queries.updateFileProgress.run(overall, file.id);
         lastWrittenProgress = overall;
       }
     };
     ```

     Key points:
     - `lastWrittenProgress` is shared across all variations of a single file (persists between iterations)
     - `onProgress` is recreated each iteration to capture current `i` value
     - Throttle: only write to DB if progress changed by >= 2% since last write (avoids excessive writes)
  8. After all variations complete, set progress to 100: `queries.updateFileProgress.run(100, file.id)`

  Import dependencies:
  ```javascript
  import fs from 'node:fs';
  import path from 'node:path';
  import { spawnFFmpeg, getVideoDuration } from './ffmpeg.js';
  import { generateUniqueEffects, buildFilterString } from './effects.js';
  import { generateId } from './id.js';
  ```

  Error handling per variation: If a single variation fails, throw the error up to the file level. The file is considered failed. Do NOT try to salvage partial variations of one file -- either all variations for a file succeed or the file is marked failed. This is simpler and matches v1 behavior (all-or-nothing per source video).
  </action>
  <verify>
  `node -e "import('./server/lib/processor.js').then(m => { console.log('processJob type:', typeof m.processJob); })"` -- should print 'function'.

  Verify imports resolve: `node -e "import('./server/lib/processor.js').catch(e => console.error('Import error:', e.message))"` -- no import errors.
  </verify>
  <done>
  processor.js exports processJob(job, db, queries, outputDir). It processes each file independently (failed file doesn't block others). For each file: probes duration, generates N unique effects, spawns FFmpeg N times, updates progress in SQLite, records output files. Progress tracks across all variations of a file.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create job queue worker with SQLite polling</name>
  <files>server/lib/queue.js</files>
  <action>
  Create `server/lib/queue.js` that exports a `JobQueueWorker` class:

  ```javascript
  import { processJob } from './processor.js';

  export class JobQueueWorker {
    constructor(db, queries, outputDir) {
      this.db = db;
      this.queries = queries;
      this.outputDir = outputDir;
      this.isRunning = false;
      this.pollTimer = null;
      this.currentJobId = null;  // Track what we're working on
    }

    start() {
      this.isRunning = true;
      console.log('Job queue worker started');
      this.poll();
    }

    stop() {
      this.isRunning = false;
      if (this.pollTimer) {
        clearTimeout(this.pollTimer);
        this.pollTimer = null;
      }
      console.log('Job queue worker stopped');
    }

    async poll() {
      if (!this.isRunning) return;

      try {
        const nextJob = this.queries.getNextQueuedJob.get();

        if (nextJob) {
          this.currentJobId = nextJob.id;
          console.log(`Processing job ${nextJob.id} (${nextJob.total_videos} videos, ${nextJob.total_variations} variations)`);

          try {
            await processJob(nextJob, this.db, this.queries, this.outputDir);
            console.log(`Job ${nextJob.id} completed`);
          } catch (err) {
            console.error(`Job ${nextJob.id} failed:`, err.message);
            this.queries.updateJobError.run(err.message, nextJob.id);
          }

          this.currentJobId = null;

          // Immediately check for next job (no delay between jobs)
          if (this.isRunning) {
            setImmediate(() => this.poll());
            return;
          }
        }
      } catch (err) {
        console.error('Queue poll error:', err.message);
      }

      // No job found or error -- poll again in 2 seconds
      if (this.isRunning) {
        this.pollTimer = setTimeout(() => this.poll(), 2000);
      }
    }

    getCurrentJobId() {
      return this.currentJobId;
    }
  }
  ```

  Key behaviors:
  - **Fire-and-forget (PROC-05):** Worker runs independently of HTTP connections. Once a job is queued via POST /api/jobs, the worker picks it up regardless of whether the client is still connected.
  - **Single-threaded:** Only one job processes at a time. After completing a job, immediately check for the next one (setImmediate). If no jobs, wait 2 seconds before polling again.
  - **Error isolation:** If processJob throws an unexpected error (beyond per-file errors), catch it and mark the job as failed. The worker continues polling for the next job.
  - **Stoppable:** The `stop()` method sets isRunning=false and clears the poll timer. The currently running processJob will finish naturally (it's async and runs to completion). Plan 07-03 will add signal-based FFmpeg killing on top.
  - **currentJobId tracking:** Exposed via getter so shutdown logic can know which job was interrupted.
  </action>
  <verify>
  `node -e "import('./server/lib/queue.js').then(m => { const w = new m.JobQueueWorker(null, null, null); console.log('Worker created, isRunning:', w.isRunning); console.log('Methods:', Object.getOwnPropertyNames(Object.getPrototypeOf(w)).filter(n => n !== 'constructor')); })"` -- should show isRunning: false and list start, stop, poll, getCurrentJobId methods.
  </verify>
  <done>
  queue.js exports JobQueueWorker class. Worker polls SQLite every 2 seconds for queued jobs. Processes one job at a time via processJob(). Immediately checks for next job after completion. Handles errors gracefully without crashing. Stoppable via stop() method. Fire-and-forget behavior: processing is decoupled from HTTP request lifecycle.
  </done>
</task>

</tasks>

<verification>
1. processor.js imports resolve cleanly (ffmpeg.js, effects.js, id.js)
2. queue.js imports resolve cleanly (processor.js)
3. JobQueueWorker can be instantiated
4. processJob has correct function signature
5. Error handling: per-file failures don't block batch (verified by reading code logic)
</verification>

<success_criteria>
- processJob iterates all files in a job, generating variationsPerVideo variations per file
- Each variation uses a unique random effect combination from effects.js
- Progress percentage updates in SQLite as encoding proceeds
- Failed files are marked as 'failed' with error message, processing continues to next file
- Queue worker polls every 2 seconds, processes one job at a time
- Worker is stoppable and tracks current job ID
</success_criteria>

<output>
After completion, create `.planning/phases/07-ffmpeg-processing-engine/07-02-SUMMARY.md`
</output>
